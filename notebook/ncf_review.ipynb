{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c2f7f6c61e279ec5",
   "metadata": {},
   "source": [
    "- Neural Collaborative Filtering [https://arxiv.org/pdf/1708.05031]\n",
    "- Neural Collaborative Filtering 리뷰 [https://leehyejin91.github.io/post-ncf/]\n",
    "- 최대우도법 (MLE) [https://angeloyeo.github.io/2020/07/17/MLE.html]\n",
    "- PyTorch Embedding [https://wikidocs.net/64779]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b0fe15fb7547122c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-13T06:24:09.246653Z",
     "start_time": "2024-05-13T06:24:02.434313Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.sparse as sp\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "device = \"mps\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faabf6d128e1c961",
   "metadata": {},
   "source": [
    "# 2. Preliminaries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98aff85c79c81624",
   "metadata": {},
   "source": [
    "- $U$: Set of Users\n",
    "- $I$: Set of Items\n",
    "- $M = |U|$; 즉, # of Users\n",
    "- $N = |I|$; 즉, # of Items\n",
    "- $Y$: user$\\times$item 행렬 (shape=($M$, $N$)); $Y_{u,i}=1$은 user $u$과 item $i$간의 상호작용이 존재했음을 의미\n",
    "\n",
    "> 상호작용이란 user가 item을 열람했거나, 구매했거나 등의 암시적인(implicit) 정보를 의미하며, 주의할 점은 이것이 명시적인(explicit) 선호를 뜻하진 않는다는 것이다.<br/>\n",
    "> 따라서 $Y_{u,i}=0$ 은 상호작용이 없는 것이지, 해당 item을 비선호 한다는 의미는 아니다.<br/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1728246daef6880",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-13T06:24:09.262879Z",
     "start_time": "2024-05-13T06:24:09.248269Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[1., 0., 1., 1., 0.],\n",
       "        [0., 1., 0., 0., 1.],\n",
       "        [1., 1., 1., 0., 0.],\n",
       "        [0., 0., 0., 1., 1.]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "demo_M = 4\n",
    "demo_N = 5\n",
    "\n",
    "demo_k = 2\n",
    "\n",
    "demo_Y_sparse_indices_df = pd.DataFrame([\n",
    "    [0, 0],\n",
    "    [0, 2],\n",
    "    [0, 3],\n",
    "    [1, 1],\n",
    "    [1, 4],\n",
    "    [2, 0],\n",
    "    [2, 1],\n",
    "    [2, 2],\n",
    "    [3, 3],\n",
    "    [3, 4],\n",
    "], columns=['user_id', 'item_id'])\n",
    "\n",
    "def build_Y(sparse_indices_df, _M, _N):\n",
    "    return sp.coo_matrix(([1.0] * len(sparse_indices_df), (sparse_indices_df['user_id'], sparse_indices_df['item_id'])), shape=(_M, _N))\n",
    "\n",
    "demo_Y = build_Y(demo_Y_sparse_indices_df, demo_M, demo_N)\n",
    "demo_Y.todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9c562cba72491342",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-13T06:24:09.368622Z",
     "start_time": "2024-05-13T06:24:09.263974Z"
    }
   },
   "outputs": [],
   "source": [
    "demo_u = []\n",
    "demo_i = []\n",
    "demo_y = []\n",
    "demo_Y_dense = demo_Y.todense()\n",
    "for u in range(demo_Y.shape[0]):\n",
    "    for i in range(demo_Y.shape[1]):\n",
    "        demo_u.append(u)\n",
    "        demo_i.append(i)\n",
    "        demo_y.append([demo_Y_dense[u, i]])\n",
    "\n",
    "demo_u = torch.tensor(demo_u).to(device)\n",
    "demo_i = torch.tensor(demo_i).to(device)\n",
    "demo_y = torch.tensor(demo_y).to(device, dtype=torch.float)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c8da5e341dc6153",
   "metadata": {},
   "source": [
    "# 3. Neural Collaborative Filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8192aabea5680fe0",
   "metadata": {},
   "source": [
    "## 3.1 General Framework Design"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92f3e144797a5ad",
   "metadata": {},
   "source": [
    "![](./img/mlp.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a838ee6e73cab26",
   "metadata": {},
   "source": [
    "### 3.1.1. Embedding Layer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea21007117672707",
   "metadata": {},
   "source": [
    "- $P$: shape=($M$, $k$)\n",
    "- $Q$: shape=($N$, $k$)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fe97eebd11aa1030",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-13T06:24:09.378650Z",
     "start_time": "2024-05-13T06:24:09.371051Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 2])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# User Lookup Table (P)\n",
    "demo_P = nn.Embedding(num_embeddings=demo_M, embedding_dim=demo_k) # U x user latent vector, shape=(M, k)\n",
    "demo_P.weight.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d13feeb490aaf02e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-13T06:24:09.383010Z",
     "start_time": "2024-05-13T06:24:09.379696Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 2])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Item Lookup Table (Q)\n",
    "demo_Q = nn.Embedding(num_embeddings=demo_N, embedding_dim=demo_k) # I x item latent vector, shape=(N, k)\n",
    "demo_Q.weight.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "342fbb326080ff65",
   "metadata": {},
   "source": [
    "- $v^U_u$: user $u$를 나타내는 one-hot 벡터; shape=($n$, $M$)\n",
    "- $v^I_i$: user $u$를 나타내는 one-hot 벡터; shape=($n$, $N$)\n",
    "<br/>\n",
    "<br/>\n",
    "- $p_u=v^U_uP$: shape=($n$, $k$): user latent vector\n",
    "- $q_u=v^I_iP$: shape=($n$, $k$): item latent vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "519a448a15a25fef",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-13T06:24:10.176159Z",
     "start_time": "2024-05-13T06:24:10.172475Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "demo_n = len(demo_Y_sparse_indices_df) # batch size\n",
    "demo_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3532a4382a9ba097",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-13T06:24:10.186836Z",
     "start_time": "2024-05-13T06:24:10.177751Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 2])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# User Latent Vector\n",
    "demo_p_u = demo_P(torch.tensor(demo_Y_sparse_indices_df['user_id'])) # shape=(n, k)\n",
    "demo_p_u.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "13f509f5342d058f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-13T06:24:10.337333Z",
     "start_time": "2024-05-13T06:24:10.333165Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 2])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Item Latent Vector\n",
    "demo_q_u = demo_Q(torch.tensor(demo_Y_sparse_indices_df['item_id'])) # shape=(n, k)\n",
    "demo_q_u.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0382c2b06179679",
   "metadata": {},
   "source": [
    "### 3.1.2. Neural CF Layers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ff747e23b3b4478",
   "metadata": {},
   "source": [
    "$$\n",
    "\\Phi_1(p_u, q_u) = [p_u, q_u]\\\\\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "406902b815369119",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-13T06:24:13.206927Z",
     "start_time": "2024-05-13T06:24:13.200722Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 4])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "demo_phi_1 = torch.cat((demo_p_u, demo_q_u), -1) # BATCH x (user latent vector, item latent vector), shape=(n, k+k)\n",
    "demo_phi_1.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b553eab059c73b5d",
   "metadata": {},
   "source": [
    "논문에 따르면\n",
    "- Bottom Layer가 넓고 순차적으로 Neuron수를 반씩 줄여나가는 Tower Pattern으로 구현\n",
    "- 활성화 함수로 ReLU를 사용하는것이 결과적으로 조금더 괜찮은 성능을 보임\n",
    "\n",
    "추가적으로 Hidden Layer에 성능을 높이기 위해 Dropout Layer를 추가함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "18736d213e1ec4c5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-13T06:24:20.953079Z",
     "start_time": "2024-05-13T06:24:15.849048Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 2])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def create_layer(_input_size, dropout_prob=0.5):\n",
    "    output_size = _input_size // 2\n",
    "    return nn.Sequential(\n",
    "        nn.Dropout(p=dropout_prob),\n",
    "        nn.Linear(_input_size, output_size),\n",
    "        nn.ReLU(),\n",
    "    ), output_size\n",
    "\n",
    "num_layers = 1\n",
    "\n",
    "input_size = demo_k * 2\n",
    "layers = []\n",
    "for i in range(num_layers):\n",
    "    layer, input_size = create_layer(input_size)\n",
    "    layers.append(layer)\n",
    "demo_phi_X = nn.Sequential(*layers)(demo_phi_1)\n",
    "demo_phi_X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beb6ae30578df228",
   "metadata": {},
   "source": [
    "### 3.1.3. Output Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ec16455814c7e7d7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-13T06:24:20.963150Z",
     "start_time": "2024-05-13T06:24:20.955869Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.4513],\n",
       "        [-0.4513],\n",
       "        [-0.5988],\n",
       "        [-0.4513],\n",
       "        [-0.5849],\n",
       "        [ 0.1692],\n",
       "        [-0.5125],\n",
       "        [-0.5742],\n",
       "        [-0.3045],\n",
       "        [-0.4513]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phi_out = nn.Linear(input_size, 1)(demo_phi_X)\n",
    "phi_out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "226f3585f6f90686",
   "metadata": {},
   "source": [
    "### 3.1.4. General Framework Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7f3ff43f9bbd327b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-13T06:24:20.972586Z",
     "start_time": "2024-05-13T06:24:20.965130Z"
    }
   },
   "outputs": [],
   "source": [
    "class NCFFramework(nn.Module):\n",
    "    @staticmethod\n",
    "    def __create_layer(in_size, dropout_prob=0.5):\n",
    "        out_size = in_size // 2\n",
    "        return nn.Sequential(\n",
    "            nn.Dropout(p=dropout_prob),\n",
    "            nn.Linear(in_size, out_size),\n",
    "            nn.ReLU(),\n",
    "        ), out_size \n",
    "    \n",
    "    def __init__(self, M, N, ncfl_num_layers, ncfl_out_size, dropout_prob=0.5):\n",
    "        super(NCFFramework, self).__init__()\n",
    "        \n",
    "        self.M = M\n",
    "        self.N = N\n",
    "        \n",
    "        assert ncfl_num_layers >= 1, \"Neural CF layers should have at least one layer.\"\n",
    "        self.ncfl_num_layers = ncfl_num_layers # Number of layers in 'neural collaborative filtering layers'\n",
    "\n",
    "        self.ncfl_in_size = ((2 ** self.ncfl_num_layers) * ncfl_out_size)\n",
    "        self.ncfl_out_size = ncfl_out_size # 'neural collaborative filtering layers' output dimension\n",
    "        \n",
    "        self.embedding_dim = self.ncfl_in_size // 2\n",
    "        \n",
    "        self.P = nn.Embedding(num_embeddings=self.M, embedding_dim=self.embedding_dim)\n",
    "        self.Q = nn.Embedding(num_embeddings=self.N, embedding_dim=self.embedding_dim)\n",
    "        \n",
    "        last_out_size = self.ncfl_in_size\n",
    "        layers = []\n",
    "        for i in range(self.ncfl_num_layers):\n",
    "            layer, last_out_size = NCFFramework.__create_layer(last_out_size, dropout_prob)\n",
    "            layers.append(layer)\n",
    "        self.phi_X = nn.Sequential(*layers)\n",
    "        \n",
    "        self.phi_out = nn.Linear(last_out_size, 1)\n",
    "        \n",
    "        self.__init_weights()\n",
    "        \n",
    "    def __init_weights(self):\n",
    "        nn.init.normal_(self.P.weight, std=.01)\n",
    "        nn.init.normal_(self.Q.weight, std=.01)\n",
    "        \n",
    "        for phi in self.phi_X:\n",
    "            for phi_layer in phi:\n",
    "                if isinstance(phi_layer, nn.Linear):\n",
    "                    nn.init.xavier_uniform_(phi_layer.weight)\n",
    "                    phi_layer.bias.data.zero_()\n",
    "                \n",
    "        nn.init.kaiming_uniform_(self.phi_out.weight, nonlinearity=\"sigmoid\")\n",
    "        self.phi_out.bias.data.zero_()\n",
    "        \n",
    "    def forward(self, user_id, item_id):\n",
    "        p_u = self.P(user_id)\n",
    "        q_i = self.Q(item_id)\n",
    "        \n",
    "        phi_1_result = torch.cat((p_u, q_i), -1)\n",
    "        phi_X_result = self.phi_X(phi_1_result)\n",
    "        return self.phi_out(phi_X_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "395adbfb9b13d28f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-13T06:24:25.722352Z",
     "start_time": "2024-05-13T06:24:25.708990Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NCFFramework(\n",
       "  (P): Embedding(4, 128)\n",
       "  (Q): Embedding(5, 128)\n",
       "  (phi_X): Sequential(\n",
       "    (0): Sequential(\n",
       "      (0): Dropout(p=0.3, inplace=False)\n",
       "      (1): Linear(in_features=256, out_features=128, bias=True)\n",
       "      (2): ReLU()\n",
       "    )\n",
       "    (1): Sequential(\n",
       "      (0): Dropout(p=0.3, inplace=False)\n",
       "      (1): Linear(in_features=128, out_features=64, bias=True)\n",
       "      (2): ReLU()\n",
       "    )\n",
       "    (2): Sequential(\n",
       "      (0): Dropout(p=0.3, inplace=False)\n",
       "      (1): Linear(in_features=64, out_features=32, bias=True)\n",
       "      (2): ReLU()\n",
       "    )\n",
       "  )\n",
       "  (phi_out): Linear(in_features=32, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "demo_model = NCFFramework(demo_M, demo_N, ncfl_num_layers=3, ncfl_out_size=32, dropout_prob=0.3).to(device)\n",
    "demo_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "debc0a768f7b9efd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-13T06:24:29.596015Z",
     "start_time": "2024-05-13T06:24:29.108556Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0040],\n",
       "        [-0.0008],\n",
       "        [ 0.0277],\n",
       "        [ 0.0113],\n",
       "        [ 0.0110],\n",
       "        [ 0.0032],\n",
       "        [ 0.0080],\n",
       "        [ 0.0104],\n",
       "        [ 0.0105],\n",
       "        [ 0.0169],\n",
       "        [ 0.0109],\n",
       "        [ 0.0137],\n",
       "        [ 0.0146],\n",
       "        [ 0.0135],\n",
       "        [ 0.0019],\n",
       "        [ 0.0080],\n",
       "        [ 0.0071],\n",
       "        [ 0.0109],\n",
       "        [ 0.0113],\n",
       "        [ 0.0237]], device='mps:0', grad_fn=<LinearBackward0>)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "demo_y_hat = demo_model.forward(demo_u, demo_i)\n",
    "demo_y_hat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e666ecb98f8d9f4",
   "metadata": {},
   "source": [
    "### 3.1.5. Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db3f97e749656229",
   "metadata": {},
   "source": [
    "\n",
    "상호관계 여부를 예측하는 Binary Classification 문제이기 때문에 대표적으로 사용되는 Binary Cross Entropy Loss를 사용한다.<br/>\n",
    "모델의 output이 Sigmoid 활성화 함수를 거치지 않은 logits이기 때문에 Sigmoid 레이어가 내재화된 BCEWithLogitsLoss 손실함수를 사용한다.<br/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "514335175956576f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-13T06:24:30.411566Z",
     "start_time": "2024-05-13T06:24:30.313993Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6915115118026733"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "demo_loss_function = nn.BCEWithLogitsLoss()\n",
    "demo_loss_function(demo_y_hat, demo_y).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d3e000ae2f88e00d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-13T06:24:35.473144Z",
     "start_time": "2024-05-13T06:24:31.739684Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6929309964179993\n",
      "0.6916479468345642\n",
      "0.6865730285644531\n",
      "0.6881486773490906\n",
      "0.6858047842979431\n",
      "0.6703415513038635\n",
      "0.6391724944114685\n",
      "0.664279580116272\n",
      "0.6496123671531677\n",
      "0.5650702714920044\n",
      "0.548984944820404\n",
      "0.5117141008377075\n",
      "0.4072394371032715\n",
      "0.43329548835754395\n",
      "0.31386232376098633\n",
      "0.28013715147972107\n",
      "0.27188488841056824\n",
      "0.22473230957984924\n",
      "0.24421150982379913\n",
      "0.10248155891895294\n",
      "0.06292670220136642\n",
      "0.05329655483365059\n",
      "0.088319793343544\n",
      "0.1314503401517868\n",
      "0.013704395852982998\n",
      "0.0022017862647771835\n",
      "0.01306657213717699\n",
      "0.00787320639938116\n",
      "0.3810669481754303\n",
      "0.0012017246335744858\n",
      "0.0023655544500797987\n",
      "0.0002806294651236385\n",
      "0.09312061220407486\n",
      "0.2558099925518036\n",
      "0.008946609683334827\n",
      "0.002869856311008334\n",
      "0.017996544018387794\n",
      "0.18198277056217194\n",
      "0.06985878199338913\n",
      "0.006510592997074127\n",
      "0.30160093307495117\n",
      "0.06476017832756042\n",
      "0.0037618314381688833\n",
      "0.1319386214017868\n",
      "0.00021823789575137198\n",
      "0.020836306735873222\n",
      "0.06986329704523087\n",
      "0.03938419744372368\n",
      "0.005239080172032118\n",
      "0.14293740689754486\n",
      "0.26868128776550293\n",
      "0.020596442744135857\n",
      "0.006860449910163879\n",
      "0.17339661717414856\n",
      "0.09635201841592789\n",
      "0.008701923303306103\n",
      "0.0008244412019848824\n",
      "0.14608816802501678\n",
      "0.7983546257019043\n",
      "0.24101610481739044\n",
      "0.3594571053981781\n",
      "0.027854282408952713\n",
      "0.0007034316658973694\n",
      "0.02150842733681202\n",
      "0.0012389773037284613\n",
      "0.00751486886292696\n",
      "0.35081303119659424\n",
      "0.04765717312693596\n",
      "0.5103155970573425\n",
      "0.003524648491293192\n",
      "0.009382538497447968\n",
      "0.01585197262465954\n",
      "0.0417616069316864\n",
      "0.0267462320625782\n",
      "0.11826365441083908\n",
      "0.0774308294057846\n",
      "0.02288384921848774\n",
      "0.24053478240966797\n",
      "0.06264945864677429\n",
      "0.050452377647161484\n",
      "0.028322650119662285\n",
      "0.019000539556145668\n",
      "0.006554280407726765\n",
      "0.013655315153300762\n",
      "0.21581868827342987\n",
      "0.02032233215868473\n",
      "0.29027536511421204\n",
      "0.006309498101472855\n",
      "0.0876239761710167\n",
      "0.034777313470840454\n",
      "0.0007929868879728019\n",
      "0.0016472500283271074\n",
      "0.0024796933867037296\n",
      "0.003681478789076209\n",
      "0.0027412523049861193\n",
      "0.0009752201149240136\n",
      "0.0012858760310336947\n",
      "0.129090815782547\n",
      "0.000496555701829493\n",
      "0.1061747819185257\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 0.01\n",
    "demo_optimizer = torch.optim.Adam(demo_model.parameters(), lr=learning_rate)\n",
    "\n",
    "demo_model.train()\n",
    "\n",
    "epochs = 100\n",
    "for i in range(epochs):\n",
    "    demo_model.zero_grad()\n",
    "    demo_y_hat = demo_model(demo_u, demo_i)\n",
    "\n",
    "    loss = demo_loss_function(demo_y_hat, demo_y)\n",
    "    loss.backward()\n",
    "\n",
    "    print(loss.item())\n",
    "\n",
    "    demo_optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2379adb76ea68b92",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-13T06:24:35.506249Z",
     "start_time": "2024-05-13T06:24:35.474902Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0000e+00],\n",
       "        [2.8731e-05],\n",
       "        [1.0000e+00],\n",
       "        [9.9998e-01],\n",
       "        [6.0938e-05],\n",
       "        [7.9006e-06],\n",
       "        [1.0000e+00],\n",
       "        [5.5600e-05],\n",
       "        [7.3863e-04],\n",
       "        [1.0000e+00],\n",
       "        [1.0000e+00],\n",
       "        [1.0000e+00],\n",
       "        [1.0000e+00],\n",
       "        [9.2660e-04],\n",
       "        [5.3489e-03],\n",
       "        [1.0757e-08],\n",
       "        [6.5150e-04],\n",
       "        [5.1420e-09],\n",
       "        [9.9933e-01],\n",
       "        [9.9991e-01]], device='mps:0', grad_fn=<SigmoidBackward0>)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "demo_model.eval()\n",
    "demo_prediction = demo_model.forward(demo_u, demo_i)\n",
    "torch.sigmoid(demo_prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bc2fcd37329bb69",
   "metadata": {},
   "source": [
    "## 3.2. Neural Matrix Factorization (Generalized Matrix Factorization, GMF + Multi-Layer Perceptron, MLP)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f1f726e7e4186b3",
   "metadata": {},
   "source": [
    "![](./img/neumf.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6b0435610fb2dc00",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-13T06:30:07.509775Z",
     "start_time": "2024-05-13T06:30:07.483722Z"
    }
   },
   "outputs": [],
   "source": [
    "class NeuMF(nn.Module):\n",
    "    @staticmethod\n",
    "    def create_layer(in_size, dropout_prob=0.5):\n",
    "        out_size = in_size // 2\n",
    "        return nn.Sequential(\n",
    "            nn.Dropout(p=dropout_prob),\n",
    "            nn.Linear(in_size, out_size),\n",
    "            nn.ReLU(),\n",
    "        ), out_size\n",
    "\n",
    "    def __init__(self, M, N, predictive_factor_num, mlp_num_layers, dropout_prob=0.5):\n",
    "        super(NeuMF, self).__init__()\n",
    "\n",
    "        self.M = M\n",
    "        self.N = N\n",
    "\n",
    "        assert predictive_factor_num % 2 == 0, \"Number of predictive factor should be divisible by 2.\"\n",
    "\n",
    "        # MLP\n",
    "        assert mlp_num_layers >= 1, \"MLP should have at least one layer.\"\n",
    "\n",
    "        mlp_out_size = predictive_factor_num // 2\n",
    "        mlp_in_size = ((2 ** mlp_num_layers) * mlp_out_size)\n",
    "\n",
    "        self.mlp_embedding_dim = mlp_in_size // 2\n",
    "        self.mlp_P = nn.Embedding(num_embeddings=self.M, embedding_dim=self.mlp_embedding_dim)\n",
    "        self.mlp_Q = nn.Embedding(num_embeddings=self.N, embedding_dim=self.mlp_embedding_dim)\n",
    "\n",
    "        last_out_size = mlp_in_size\n",
    "        layers = []\n",
    "        for i in range(mlp_num_layers):\n",
    "            layer, last_out_size = NeuMF.create_layer(last_out_size, dropout_prob)\n",
    "            layers.append(layer)\n",
    "        self.mlp_layer_X = nn.Sequential(*layers)\n",
    "        # END OF MLP\n",
    "\n",
    "        # GMF\n",
    "        self.gmf_embedding_dim = predictive_factor_num // 2\n",
    "        self.gmf_P = nn.Embedding(num_embeddings=self.M, embedding_dim=self.gmf_embedding_dim)\n",
    "        self.gmf_Q = nn.Embedding(num_embeddings=self.N, embedding_dim=self.gmf_embedding_dim)\n",
    "        # END OF GMF\n",
    "\n",
    "        self.neu_mf = nn.Linear(predictive_factor_num, 1)\n",
    "\n",
    "        self.__init_weights()\n",
    "\n",
    "    def __init_weights(self):\n",
    "        nn.init.normal_(self.gmf_P.weight, std=.01)\n",
    "        nn.init.normal_(self.gmf_Q.weight, std=.01)\n",
    "\n",
    "        nn.init.normal_(self.mlp_P.weight, std=.01)\n",
    "        nn.init.normal_(self.mlp_Q.weight, std=.01)\n",
    "\n",
    "        for mlp_layer in self.mlp_layer_X:\n",
    "            for inner_layer in mlp_layer:\n",
    "                if isinstance(inner_layer, nn.Linear):\n",
    "                    nn.init.xavier_uniform_(inner_layer.weight)\n",
    "                    inner_layer.bias.data.zero_()\n",
    "\n",
    "        nn.init.kaiming_uniform_(self.neu_mf.weight, nonlinearity=\"sigmoid\")\n",
    "        self.neu_mf.bias.data.zero_()\n",
    "\n",
    "    def forward(self, user_id, item_id):\n",
    "        # GMF\n",
    "        gfm_p_u = self.gmf_P(user_id)\n",
    "        gfm_q_i = self.gmf_Q(item_id)\n",
    "        gfm_out = torch.multiply(gfm_p_u, gfm_q_i)\n",
    "\n",
    "        # MLP\n",
    "        mlp_p_u = self.mlp_P(user_id)\n",
    "        mlp_q_i = self.mlp_Q(item_id)\n",
    "        layer_1_out = torch.cat((mlp_p_u, mlp_q_i), -1)\n",
    "        mlp_out = self.mlp_layer_X(layer_1_out)\n",
    "\n",
    "        neu_cf_in = torch.cat((gfm_out, mlp_out), -1)\n",
    "        return self.neu_mf(neu_cf_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c4e110850626082d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-13T06:30:11.785855Z",
     "start_time": "2024-05-13T06:30:08.018391Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6937944889068604\n",
      "0.6931107640266418\n",
      "0.6945368647575378\n",
      "0.6925746202468872\n",
      "0.6922988295555115\n",
      "0.6909939646720886\n",
      "0.6915990114212036\n",
      "0.6902710199356079\n",
      "0.6903945207595825\n",
      "0.6832013130187988\n",
      "0.6844273805618286\n",
      "0.6832268834114075\n",
      "0.6834337115287781\n",
      "0.6690720915794373\n",
      "0.6843172907829285\n",
      "0.6848973631858826\n",
      "0.6755701303482056\n",
      "0.6706559062004089\n",
      "0.7047848701477051\n",
      "0.6637685298919678\n",
      "0.6622054576873779\n",
      "0.6623641848564148\n",
      "0.6597537994384766\n",
      "0.672028660774231\n",
      "0.6179949641227722\n",
      "0.6390998363494873\n",
      "0.6626035571098328\n",
      "0.6291914582252502\n",
      "0.6434594988822937\n",
      "0.6338084936141968\n",
      "0.598013162612915\n",
      "0.6148225665092468\n",
      "0.6113141775131226\n",
      "0.5853621959686279\n",
      "0.5767350792884827\n",
      "0.5816375613212585\n",
      "0.5522779822349548\n",
      "0.5281620621681213\n",
      "0.5018259882926941\n",
      "0.5415157675743103\n",
      "0.5321045517921448\n",
      "0.5060431361198425\n",
      "0.49864616990089417\n",
      "0.45321089029312134\n",
      "0.4529767632484436\n",
      "0.42777082324028015\n",
      "0.43425512313842773\n",
      "0.4173538386821747\n",
      "0.4217115342617035\n",
      "0.4546630382537842\n",
      "0.3612145483493805\n",
      "0.3771856725215912\n",
      "0.3665814995765686\n",
      "0.35903629660606384\n",
      "0.3888198435306549\n",
      "0.35856544971466064\n",
      "0.31738734245300293\n",
      "0.3092444837093353\n",
      "0.3011520802974701\n",
      "0.282762348651886\n",
      "0.26687297224998474\n",
      "0.26480868458747864\n",
      "0.2710738182067871\n",
      "0.2370191067457199\n",
      "0.2194700688123703\n",
      "0.2275320589542389\n",
      "0.20662029087543488\n",
      "0.2053031176328659\n",
      "0.23368237912654877\n",
      "0.1868935525417328\n",
      "0.1589653491973877\n",
      "0.14741018414497375\n",
      "0.14047543704509735\n",
      "0.13174210488796234\n",
      "0.1265556365251541\n",
      "0.10617595165967941\n",
      "0.1378156542778015\n",
      "0.10109949111938477\n",
      "0.08730068057775497\n",
      "0.07517602294683456\n",
      "0.07327020168304443\n",
      "0.07073235511779785\n",
      "0.06794080883264542\n",
      "0.06169533729553223\n",
      "0.055590033531188965\n",
      "0.048776622861623764\n",
      "0.052781689912080765\n",
      "0.049610238522291183\n",
      "0.045743122696876526\n",
      "0.03760618716478348\n",
      "0.039667289704084396\n",
      "0.03305681794881821\n",
      "0.032770972698926926\n",
      "0.02947286330163479\n",
      "0.02743728831410408\n",
      "0.025015342980623245\n",
      "0.023844074457883835\n",
      "0.025508064776659012\n",
      "0.02275436371564865\n",
      "0.019655581563711166\n"
     ]
    }
   ],
   "source": [
    "demo_ncf_model = NeuMF(demo_M, demo_N, predictive_factor_num=8, mlp_num_layers=3).to(device)\n",
    "\n",
    "demo_ncf_loss_function = nn.BCEWithLogitsLoss()\n",
    "\n",
    "learning_rate = 0.01\n",
    "demo_ncf_optimizer = torch.optim.Adam(demo_ncf_model.parameters(), lr=learning_rate)\n",
    "\n",
    "epochs = 100\n",
    "demo_ncf_model.train()\n",
    "for i in range(epochs):\n",
    "    demo_ncf_model.zero_grad()\n",
    "    demo_y_hat = demo_ncf_model(demo_u, demo_i)\n",
    "\n",
    "    loss = demo_ncf_loss_function(demo_y_hat, demo_y)\n",
    "    loss.backward()\n",
    "\n",
    "    print(loss.item())\n",
    "\n",
    "    demo_ncf_optimizer.step()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
